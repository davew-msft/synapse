## Working with Data in a Data Lake - Data Discovery/Sandboxing

Discussion points:
* query-in-place vs data loading

### Data Exploration

1. Launch Synapse Studio
1. Look at our sale-small data in the lake using serverless.  Let's use some examples:

I want to see all sales for 1/1/2018.  First, find the data by drilling downn in the workspace.  

Note that: 
* we are using our serverless (on-demand) sql pool for data exploration
* you will need to change the storage account in the queries below
* note _what_ we are changing in the queries as each requirement changes

Right click and choose `SELECT TOP 100`.  The query should look like this:

```sql
SELECT
    TOP 100 *
FROM
    OPENROWSET(
        BULK 'https://asadatalakedavew891.dfs.core.windows.net/wwi-02/sale-small/Year=2018/Quarter=Q1/Month=1/Day=20180101/sale-small-20180101-snappy.parquet',
        FORMAT='PARQUET'
    ) AS [result]
```

Now modify that to tell me the total sales for that day:

```sql
SELECT
    count_big(*)
FROM
    OPENROWSET(
        BULK 'https://asadatalakedavew891.dfs.core.windows.net/wwi-02/sale-small/Year=2018/Quarter=Q1/Month=1/Day=20180101/sale-small-20180101-snappy.parquet',
        FORMAT='PARQUET'
    ) AS [result]
```

Now I want to see the total count of sales for all of 2018:

```sql
SELECT
    count_big(*)
FROM
    OPENROWSET(
        BULK 'https://asadatalakedavew891.dfs.core.windows.net/wwi-02/sale-small/Year=2018/*/*/*/*',
        FORMAT='PARQUET'
    ) AS [result]
```

Find the SUM and AVG Profit by day for each day in 2018 Q4

```sql
SELECT
    TransactionDate,
    CAST(SUM(ProfitAmount) AS decimal(18,2)) AS [(sum) Profit],
    CAST(AVG(ProfitAmount) AS decimal(18,2)) AS [(avg) Profit]
FROM
    OPENROWSET(
        BULK 'https://asadatalakedavew891.dfs.core.windows.net/wwi-02/sale-small/Year=2018/Quarter=Q4/*/*/*',
        FORMAT='PARQUET'
    ) AS [result]
GROUP BY TransactionDate
ORDER BY TransactionDate
```

## CSV files

Let's take a look at a CSV file.  Do a SELECT TOP 100 against `wwi-02/data-generators/generator-product/generator-product.csv`.  The code should look like this:

```sql
-- This is auto-generated code
SELECT
    TOP 100 *
FROM
    OPENROWSET(
        BULK 'https://asadatalakedavew891.dfs.core.windows.net/wwi-02/data-generators/generator-product/generator-product.csv',
        FORMAT = 'CSV',
        PARSER_VERSION='2.0'
    ) AS [result]
```

Notice the column headers aren't right.  We can fix that like this:

```sql
-- This is auto-generated code
SELECT
    TOP 100 *
FROM
    OPENROWSET(
        BULK 'https://asadatalakedavew891.dfs.core.windows.net/wwi-02/data-generators/generator-product/generator-product.csv',
        FORMAT = 'CSV',
        PARSER_VERSION='2.0',
        FIRSTROW = 1)
        WITH (
            ProductID INT,
            Seasonality INT,
            Price DECIMAL(10,2),
            Profit DECIMAL(10,2)
        ) as csv
```

Much better.  

Note that we can also chart this data.


## JSON data

Do a SELECT TOP 100 against `product-json/json-data/product-1.json`.  The code should look like this:

```sql
-- This is auto-generated code
SELECT TOP 100
    jsonContent
/* --> place the keys that you see in JSON documents in the WITH clause:
       , JSON_VALUE (jsonContent, '$.key1') AS header1
       , JSON_VALUE (jsonContent, '$.key2') AS header2
*/
FROM
    OPENROWSET(
        BULK 'https://asadatalakedavew891.dfs.core.windows.net/wwi-02/product-json/json-data/product-1.json',
        FORMAT = 'CSV',
        FIELDQUOTE = '0x0b',
        FIELDTERMINATOR ='0x0b',
        ROWTERMINATOR = '0x0b'
    )
    WITH (
        jsonContent varchar(MAX)
    ) AS [result]
```

Yuk.  Horrible.

Rather than explain how to fix it, here's the pattern you can use and here's what we changed:

* we want to query all json files, not just that one.  Use a wildcard.
* add the `CROSS APPLY` statement to declare the schema
* use an alias and subsequently change the `SELECT` projection
* note that you'll get 5 rows...one for each file

```sql
SELECT products.*
FROM
    OPENROWSET(
        BULK 'https://asadatalakedavew891.dfs.core.windows.net/wwi-02/product-json/json-data/*.json',
        FORMAT = 'CSV',
        FIELDQUOTE = '0x0b',
        FIELDTERMINATOR ='0x0b',
        ROWTERMINATOR = '0x0b'
    )
    WITH (
        jsonContent varchar(MAX)
    ) AS [result]
CROSS APPLY OPENJSON(jsonContent)
WITH (
    ProductId INT,
    Seasonality INT,
    Price DECIMAL(10,2),
    Profit DECIMAL(10,2)
) AS products

```

### Automatic Schema Discovery

* if you ever see errors, try specifying the `WITH` clause where you specify the schema.  Usually this is enough to "trick" Synapse into understanding the file.  [Documentation](https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-openrowset#automatic-schema-discovery)
  * this often happens if an empty folder is encountered
* Sometimes (one of) the file(s) is corrupt but specifying only the needed columns is enough to trick it too.  
* automatic schema discovery works great for Parquet where the schema is tightly coupled with the file format.  That's not the case with csv.  If you use inferred schemas with csvs it can often cause poor performance.  Instead try running this:  `EXEC sp_describe_first_result_set` and then declare the schema as part of the WITH clause.  Never do inferred schemas when moving an ETL pipeline to production.  


