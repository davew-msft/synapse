## Lab 057:  Loading Data from a Data Lake into Synapse SQL Pool using the "Integrate" box-and-line experience (ADF)

### Business Objective

Let's assume our `customerinfo.csv` data is already prepped in our `gold` area and we want to load it into `dimCustomer` as-is, in our EDW.  

### Implementation

* Let's use the `Integrate` box-and-line tool to do this.  
* we decide we do not need SCD2 or any fancy surrogate keys.  Let's keep this simple.  
* we also know our customer list is quite short so we decide we can use `REPLICATE` for our distribution strategy.  
* A CCI almost always makes the right sense for a dimension table.  
* We decide on this schema:

```sql
 CREATE TABLE [warehouse].[dimCustomer]
 (
   [UserName] [nvarchar](100)  NULL,
   [Gender] [nvarchar](10)  NULL,
   [Phone] [nvarchar](50)  NULL,
   [Email] [nvarchar](150)  NULL,
   [CreditCard] [nvarchar](21)  NULL
 )
 WITH
 (
   DISTRIBUTION = REPLICATE,
   CLUSTERED COLUMNSTORE INDEX
 )
 GO
```

## Lab

* Make sure your SQL Pool (the MPP EDW feature of Synapse) is running.  
  * DWU100 is adequate
* Please run [scripts/edw-tables.sql](./scripts/edw-tables.sql) against your SQL Pool to create the required objects, if you haven't done so already.  



1. From the left menu, select **Data**. From the **Data** blade, expand the **+** button and select **Integration Dataset**.

2. On the **New integration dataset** blade, with the **Azure** tab selected, choose the **Azure Data Lake Gen2** item. Select **Continue**.  
  
3. On the **Select format** blade, select **CSV Delimited Text**. Select **Continue**.


4. On the **Set properties** blade, set the fields to the following values, then select **OK**.

   | Field | Value |
   |-------|-------|
   | Name  | Enter **asamcw_customerinfo_csv**. |
   | File Path - Container | Enter **wwi-02**. |
   | File Path - Directory | Enter **customer-info**. |
   | File Path - File | Enter **customerinfo.csv**. |
   | First row as header | Checked |
   | Import schema | Select **From connection/store**. |

5. Now we will need to define the destination dataset for our data. In this case we will be storing customer information data in our SQL Pool. On the **Data** blade, expand the **+** button and select **Integration dataset**.

6. On the **New integration dataset** blade, with the **Azure** tab selected, enter **synapse** as a search term and select the **Azure Synapse Analytics (formerly SQL DW)** item. Select **Continue**.

7. On the **Set properties** blade, set the field values to connect to `warehouse.dimCustomer`

8. In the top toolbar, select **Publish all** to publish the new dataset definitions. When prompted, select the **Publish** button to commit the changes.

9. Next, we will define a pipeline to populate data into the CustomerInfo table. From the left menu, select **Integrate**. From the Integrate blade, select the **+** button and select the **Pipeline** item.

1. In the **Activities** menu, expand the **Move & transform** item. Drag an instance of the **Copy data** activity to the design surface of the pipeline.

1. Complete the remaining steps and test the pipeline.  

    * For **Pre-copy script** on the sink tab enter:

    ```sql
      truncate table wwi_mcw.CustomerInfo
    ```
