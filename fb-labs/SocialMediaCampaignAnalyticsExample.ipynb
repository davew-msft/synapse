{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "<div class=\"alert alert-info\" role=\"alert\">\r\n",
        "    <center><h1 style=\"color:red;\"><strong><font color = red>Social Media Campaign Analytics:<br>Should we INCREASE our investment in social media marketing?\r\n",
        "    <br>--or--\r\n",
        "    <br>The Problem with Sampling</font></strong></h1></center><br>\r\n",
        "</div>\r\n",
        "<br><br>\r\n",
        "\r\n",
        "`Whenever you deal with a \"sampling\" problem you need to be VERY careful when drawing conclusions.  Think about every election that\r\n",
        "was predicted to be a landslide, but wasn't.  Let's look at a marketing example.`\r\n",
        "\r\n",
        "## Business Problem \r\n",
        "\r\n",
        "You are a business analyst, called to a meeting with your executive team to help with some marketing analytics.  CMO Sheila says,...\r\n",
        "\r\n",
        "![](https://raw.githubusercontent.com/davew-msft/PrescriptiveAnalytics/sparkconf/slides/cmo.jpg)\r\n",
        "\r\n",
        ">Last quarter was the best quarter in our history.  We crushed Wall Streets earning targets by a wide margin.  I am POSITIVE \r\n",
        "that the **key reason** was our **revamped digital advertising campaigns**.  Last summer we conducted a **comprehensive** survey \r\n",
        "of our social media usage at our **mall stores** which I plotted in this **pie chart**:\r\n",
        "\r\n",
        "![](https://raw.githubusercontent.com/davew-msft/PrescriptiveAnalytics/sparkconf/slides/pieChart.png)\r\n",
        "\r\n",
        "She continues...\r\n",
        "\r\n",
        ">You can see from the pie chart that our **Instagram presence is expanding**. 52% of survey respondents said they learned \r\n",
        "about our company from Instagram. **We should double-down on our Instagram ads** to continue our earnings growth \r\n",
        "trajectory.\r\n",
        "\r\n",
        "### Your CEO is skeptical...\r\n",
        "\r\n",
        "...before investing more budget to targeted IG campaigns your CEO asks you to explore the data a bit.  You think it is best to do this\r\n",
        "as part of a group _Design Thinking_ session where we can interactively look at the data and problem together, hypothesize, and come \r\n",
        "to a conclusion about _what do we do next?_.  \r\n",
        "\r\n",
        ">Half of my marketing dollars are wasted.  The problem is, I don't know which half?  --John Wanamaker\r\n",
        "\r\n",
        "<img src=\"https://raw.githubusercontent.com/davew-msft/PrescriptiveAnalytics/sparkconf/slides/jw.jpg\" width=\"50\">\r\n",
        "\r\n",
        "## Design Thinking Session\r\n",
        "\r\n",
        "You think that it might be a good idea to start by looking at how the survey questions were designed.  The way questions are asked can\r\n",
        "greatly influence the outcome of a survey.  \r\n",
        "\r\n",
        ">There's a whole science behind asking questions in surveys.  Too much to write about here.  \r\n",
        "\r\n",
        "Here is the actual survey that was used: \r\n",
        "\r\n",
        "![](https://raw.githubusercontent.com/davew-msft/PrescriptiveAnalytics/sparkconf/slides/survey.png)\r\n",
        "\r\n",
        "OK.  That's a pretty simple survey.  You also find out that the folks conducting the survey were guessing at the **age range** of the\r\n",
        "respondents and capturing that information as well.  That's great!  \r\n",
        "\r\n",
        "### Possible Issues\r\n",
        "\r\n",
        "Your _Design Thinking_ team uncovers some _possible_ issues with this survey _experiment_.  And we build our hypotheses **before \r\n",
        "looking at the data**.  \r\n",
        "\r\n",
        "* There _might_ be **sampling bias**.  You could make the case that the survey is biased towards store customers that are social\r\n",
        "media users and that might not be reflective of all customers who visit the store.  CMO Sheila does *not* believe the survey was biased.  \r\n",
        "\r\n",
        "You ask to see Sheila's data and she relunctantly provides it.  \r\n",
        "\r\n",
        "## Exploratory Data Analytics\r\n",
        "\r\n",
        "It's time to look at some data.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## my standard spark template\r\n",
        "## we also load a bunch of packages via requirements.txt\r\n",
        "\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "from pyspark.sql.types import *\r\n",
        "from pyspark.sql.functions import *\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "\r\n",
        "# This notebook uses synapse.  Make sure you run requirements.txt as part of the Spark cluster setup.  \r\n",
        "# This notebook assumes you've done that\r\n",
        "\r\n",
        "\r\n",
        "# vars\r\n",
        "# https://davewdemodata.dfs.core.windows.net/lake/MarketingAnalytics/surveys.csv\r\n",
        "# let's use a SAS token so this is reproducible for everyone\r\n",
        "#\r\n",
        "\r\n",
        "storageAccount='davewdemodata'\r\n",
        "container='lake'\r\n",
        "sasToken='sv=2020-10-02&st=2021-02-17T16%3A26%3A00Z&se=2030-02-18T16%3A26%3A00Z&sr=c&sp=rl&sig=UrdPIPkBQsgvD5pZhKn0KYL0Ziyb8zaXeeLw1fhA68s%3D'\r\n",
        "lakepath='wasbs://{}@{}.blob.core.windows.net/MarketingAnalytics/surveys.csv'.format(container,storageAccount)\r\n",
        "\r\n",
        "sc._jsc.hadoopConfiguration().set(\"fs.azure.sas.{0}.{1}.blob.core.windows.net\".format(container,storageAccount), sasToken)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## let's load up the file and take a look\r\n",
        "dfSurvey = spark.read \\\r\n",
        "    .option('header','true') \\\r\n",
        "    .option('delimiter', ',') \\\r\n",
        "    .csv (lakepath)\r\n",
        "display(dfSurvey.show(5))\r\n",
        "dfSurvey.printSchema()\r\n",
        "dfSurvey.registerTempTable(\"dfSurvey\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "## start with summary to do Basic EDA (Exploratory Data Analytics)\r\n",
        "display (dfSurvey.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Interpretation\r\n",
        "\r\n",
        "![](https://raw.githubusercontent.com/davew-msft/PrescriptiveAnalytics/sparkconf/slides/results01.png)\r\n",
        "\r\n",
        "* 363 rows:  this is the total number of surveys.  Is this enough?  \r\n",
        "* ...but it looks like `Responded` is TRUE/FALSE.  After discussing you learn that there were 363 _attempts_ to get a survey answered\r\n",
        "* it looks like there is only one `SurveyDate`...that's weird.  \r\n",
        "\r\n",
        "Let's dig in with a little SQL\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Basic Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql \r\n",
        "\r\n",
        "--number responded vs not\r\n",
        "--a pie chart might be a good visual here\r\n",
        "SELECT Responded, count(*) Count\r\n",
        "from dfSurvey\r\n",
        "group by Responded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Interpretation\r\n",
        "\r\n",
        "\r\n",
        "![](https://raw.githubusercontent.com/davew-msft/PrescriptiveAnalytics/sparkconf/slides/results02.png)\r\n",
        "\r\n",
        "|||\r\n",
        "|---|---|\r\n",
        "|Respondents|128|\r\n",
        "|People who didn't respond|235|\r\n",
        "|Total Asked|363|\r\n",
        "|**Response Rate**|**35%**|\r\n",
        "\r\n",
        "**A 35% response rate is not that great.  That's a possible problem.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## _HOW_ was the survey conducted?  \r\n",
        "\r\n",
        "Sheila tells you the survey was conducted just inside the entrance of a single retail store in a California mall location \r\n",
        "**as the shoppers were leaving the store**. \r\n",
        "\r\n",
        "**That's horrible** ...but let's look closer at the data.  \r\n",
        "\r\n",
        "_When_ was the survey conducted?  \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql \r\n",
        "\r\n",
        "--dates of surveys\r\n",
        "SELECT distinct SurveyDate, date_format(to_date(SurveyDate,'MM/dd/yyyy'),'EEEE') AS DayOfWeek\r\n",
        "from dfSurvey\r\n",
        "ORDER BY SurveyDate;\r\n",
        "\r\n",
        "--time ranges of surveys\r\n",
        "SELECT \r\n",
        "    min(to_timestamp(SurveyTime, 'hh:mm:ss aa'))  AS MinSurveyTime,\r\n",
        "    max(to_timestamp(SurveyTime, 'hh:mm:ss aa'))  AS MaxSurveyTime\r\n",
        "FROM dfSurvey;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Interpretation\r\n",
        "\r\n",
        "![](https://raw.githubusercontent.com/davew-msft/PrescriptiveAnalytics/sparkconf/slides/results03.png)\r\n",
        "\r\n",
        "* Surveys were conducted on a SINGLE day, a Tuesday.  \r\n",
        "* The surveys were conducted from 9-5 on a summer day.  \r\n",
        "\r\n",
        "If we think through this we should see some red flags.  \r\n",
        "\r\n",
        "* Based on those times and the fact that this is a summer day, we should see **a lot of children or retired folks** that are not at work that day.  \r\n",
        "\r\n",
        "Sheila provides you with this summary:  \r\n",
        "\r\n",
        "|Age Bracket|Respondents|\r\n",
        "|----|----|\r\n",
        "|12-20|68%|\r\n",
        "|20-40|15%|\r\n",
        "|40-65|12%|\r\n",
        "|65+|5%|\r\n",
        "\r\n",
        "...and says...\r\n",
        "\r\n",
        ">**83% of the \"Under Age 40\" demographic** are captured in the survey and this closely matches our **target sales demographic**.  \r\n",
        "\r\n",
        "But, clearly that is misrepresenting the data.  You know that it's easy to **_confuse_ with numbers** if you aggregate the data in certain ways.  \r\n",
        "This looks like one of those cases.  While the **'Under Age 40' demographic** is our target consumer, clearly we are heavily **skewed towards children**.  \r\n",
        "\r\n",
        "_Our actual target demographic, and the ones that will spend the most, was likely at work when the survey was conducted._\r\n",
        "\r\n",
        ">One common way people make **cognitive mistakes** with data is by `inappropriately aggregating data`.  ([Simpson's \r\n",
        "Paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox) is one reason).  Be careful!!\r\n",
        "\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Interpretation\r\n",
        "\r\n",
        "\r\n",
        "Remember this chart supplied by your CMO?\r\n",
        "\r\n",
        "![](https://raw.githubusercontent.com/davew-msft/PrescriptiveAnalytics/sparkconf/slides/pieChart.png)\r\n",
        "\r\n",
        "We think a better way to display this data is:\r\n",
        "\r\n",
        "|||\r\n",
        "|---|---|\r\n",
        "||%Respondents|\r\n",
        "|All Social Media|43%|\r\n",
        "|Instagram|22%|\r\n",
        "|Facebook|9%|\r\n",
        "\r\n",
        "This is a much different way to think about this data.  There are other \"issues\" with this survey and data analysis, but I'll leave that as an exercise for the \r\n",
        "reader.  \r\n",
        "\r\n",
        "## Recommendation\r\n",
        "\r\n",
        "**The data does not support additional investments in Instagram**. If we follow the CMO's recommendation we should be aware that we will be potentially be targeting\r\n",
        "the wrong demographic.  \r\n",
        "\r\n",
        " We need to design a better experiment taking the above recommendations into consideration.\r\n",
        "   * The survey design is fundamentally flawed\r\n",
        "   * There is statistical bias in the data\r\n",
        "   * There is sampling bias in the data\r\n",
        "\r\n",
        ""
      ]
    }
  ]
}